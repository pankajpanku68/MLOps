{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3p-vMcsWX7ZK"
   },
   "source": [
    "## Deploying the model as a service "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cYCpJOvvDE7E",
    "outputId": "18c36a1e-7bb7-48b6-c569-dadac75ba67d"
   },
   "outputs": [],
   "source": [
    "#!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S9xNz5mMCfAT",
    "outputId": "ba269f8a-e25f-4270-f0f5-cce032f8fb0b"
   },
   "outputs": [],
   "source": [
    "#!pip install bentoml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "\n",
    "- Ensure that you have the same version of sklearn as the version on which the pickle file was created.\n",
    "\n",
    "- Check the sklearn version of the Google Colab platform\n",
    "- Check the sklearn version here as below\n",
    "\n",
    "Otherwise, update the sklearn version using\n",
    "\n",
    "<code> pip install -U scikit-learn==1.0.2 </code>\n",
    "\n",
    "Assuming, 1.0.2 is the version sklearn using which the pickle file was created. Change the version number accordingly after checking the version on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "w8TJUoD9Df6k"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKzPB1OgDQmf"
   },
   "source": [
    "## Download the model from Weights and Biases\n",
    "\n",
    "The model is stored under the following information\n",
    "\n",
    "- **Project name :** 'mlops_usedcar'\n",
    "- **Path to the model:** 'awesomestats/mlops_usedcar/Linear_Model_UsedCar:v2'\n",
    "\n",
    "**Note**:\n",
    "\n",
    "- Replace the key with your key of weights&biases (wandb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7PJE9ndIDO1f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_API_KEY\"] = \"dc797f600c763f09dc0ffc8637c8bcdf5bc1294b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "THqh3T_ZDaf9",
    "outputId": "56825572-f827-47c2-df9b-8c6e0ed94342"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mawesomestats\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/manaranjan/Documents/Work/IIMB/edx/MLOps/modeldeploy/wandb/run-20221119_100944-18wyp47t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/awesomestats/mlops_usedcar/runs/18wyp47t\" target=\"_blank\">volcanic-glitter-23</a></strong> to <a href=\"https://wandb.ai/awesomestats/mlops_usedcar\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project='mlops_usedcar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "64-tMM6JDkPb",
    "outputId": "23b5b3cd-59c9-4834-dc29-501415d67b1f"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-21-c6d7f96897d1>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-c6d7f96897d1>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    f\"the artifact is downloaded and stored at{artifact_dir}\"\"\u001b[0m\n\u001b[0m                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "artifact = run.use_artifact('awesomestats/mlops_usedcar/Linear_Model_UsedCar:v2', type='model')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the artifact is downloaded and stored at ./artifacts/Linear_Model_UsedCar:v2'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"the artifact is downloaded and stored at {artifact_dir}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clU8tNyHDrKS",
    "outputId": "b062613b-cfde-499e-bf7f-053becab0b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 24\r\n",
      "drwxr-xr-x  3 manaranjan  staff    96 Nov 16 15:10 \u001b[1m\u001b[36m.\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  3 manaranjan  staff    96 Nov 16 15:10 \u001b[1m\u001b[36m..\u001b[m\u001b[m\r\n",
      "-rw-r--r--  1 manaranjan  staff  8655 Nov 16 15:10 cars.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al  ./artifacts/Linear_Model_UsedCar:v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting joblib==1.2.0\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     -------------------------------------- 298.0/298.0 kB 1.8 MB/s eta 0:00:00\n",
      "Installing collected packages: joblib\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "Successfully installed joblib-1.2.0\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U joblib==1.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Pickel file into Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sNzbX1f7HAfG"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from joblib import load\n",
    "import os\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "final_model = load('C://Users//kumapank//Documents//Trainings//IIM-B Analytics Conference//Workshop//cars.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azSTk7dIYIT8"
   },
   "source": [
    "## Creating the BentoML Model Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bentoml\n",
      "  Using cached bentoml-1.0.12-py3-none-any.whl (909 kB)\n",
      "Collecting opentelemetry-instrumentation==0.35b0\n",
      "  Using cached opentelemetry_instrumentation-0.35b0-py3-none-any.whl (24 kB)\n",
      "Collecting attrs>=21.1.0\n",
      "  Using cached attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting pynvml<12\n",
      "  Using cached pynvml-11.4.1-py3-none-any.whl (46 kB)\n",
      "Collecting rich>=11.2.0\n",
      "  Using cached rich-12.6.0-py3-none-any.whl (237 kB)\n",
      "Collecting schema\n",
      "  Using cached schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
      "Collecting pip-requirements-parser>=31.2.0\n",
      "  Using cached pip_requirements_parser-32.0.0-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: packaging<22,>=20.0 in c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from bentoml) (21.3)\n",
      "Collecting uvicorn\n",
      "  Using cached uvicorn-0.20.0-py3-none-any.whl (56 kB)\n",
      "Collecting cattrs>=22.1.0\n",
      "  Using cached cattrs-22.2.0-py3-none-any.whl (35 kB)\n",
      "Collecting Jinja2>=3.0.1\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting simple-di>=0.1.4\n",
      "  Using cached simple_di-0.1.5-py3-none-any.whl (9.8 kB)\n",
      "Collecting opentelemetry-sdk==1.14.0\n",
      "  Using cached opentelemetry_sdk-1.14.0-py3-none-any.whl (94 kB)\n",
      "Collecting pathspec\n",
      "  Using cached pathspec-0.10.3-py3-none-any.whl (29 kB)\n",
      "Collecting circus!=0.17.2,>=0.17.0\n",
      "  Using cached circus-0.18.0-py3-none-any.whl (200 kB)\n",
      "Collecting starlette\n",
      "  Using cached starlette-0.23.1-py3-none-any.whl (64 kB)\n",
      "Collecting python-json-logger\n",
      "  Using cached python_json_logger-2.0.4-py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from bentoml) (2.23.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from bentoml) (5.9.4)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from bentoml) (7.1.2)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.3-cp38-cp38-win_amd64.whl (324 kB)\n",
      "Collecting pip-tools>=6.6.2\n",
      "  Using cached pip_tools-6.11.0-py3-none-any.whl (52 kB)\n",
      "Collecting prometheus-client>=0.10.0\n",
      "  Using cached prometheus_client-0.15.0-py3-none-any.whl (60 kB)\n",
      "Collecting fs\n",
      "  Using cached fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
      "Collecting deepmerge\n",
      "  Using cached deepmerge-1.1.0-py3-none-any.whl (8.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http==1.14.0\n",
      "  Using cached opentelemetry_exporter_otlp_proto_http-1.14.0-py3-none-any.whl (21 kB)\n",
      "Collecting watchfiles>=0.15.0\n",
      "  Using cached watchfiles-0.18.1-cp37-abi3-win_amd64.whl (264 kB)\n",
      "Requirement already satisfied: PyYAML>=5.0 in c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from bentoml) (5.3)\n",
      "Collecting python-multipart\n",
      "  Using cached python-multipart-0.0.5.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting opentelemetry-api==1.14.0\n",
      "  Using cached opentelemetry_api-1.14.0-py3-none-any.whl (50 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from bentoml) (2.8.1)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.35b0\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.35b0-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from bentoml) (1.22.3)\n",
      "Collecting click-option-group\n",
      "  Using cached click_option_group-0.5.5-py3-none-any.whl (12 kB)\n",
      "Collecting opentelemetry-instrumentation-aiohttp-client==0.35b0\n",
      "  Using cached opentelemetry_instrumentation_aiohttp_client-0.35b0-py3-none-any.whl (11 kB)\n",
      "Collecting opentelemetry-util-http==0.35b0\n",
      "  Using cached opentelemetry_util_http-0.35b0-py3-none-any.whl (6.7 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.35b0\n",
      "  Using cached opentelemetry_semantic_conventions-0.35b0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from bentoml) (2.1.0)\n",
      "Requirement already satisfied: setuptools>=16.0 in c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from opentelemetry-api==1.14.0->bentoml) (41.2.0)\n",
      "Collecting deprecated>=1.2.6\n",
      "  Using cached Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting googleapis-common-protos~=1.52\n",
      "  Using cached googleapis_common_protos-1.57.0-py2.py3-none-any.whl (217 kB)\n",
      "Collecting backoff<3.0.0,>=1.10.0\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting opentelemetry-proto==1.14.0\n",
      "  Using cached opentelemetry_proto-1.14.0-py3-none-any.whl (66 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from opentelemetry-instrumentation==0.35b0->bentoml) (1.13.3)\n",
      "Collecting asgiref~=3.0\n",
      "  Using cached asgiref-3.5.2-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from opentelemetry-sdk==1.14.0->bentoml) (4.0.1)\n",
      "Collecting protobuf~=3.13\n",
      "  Using cached protobuf-3.20.3-cp38-cp38-win_amd64.whl (904 kB)\n",
      "Collecting exceptiongroup\n",
      "  Using cached exceptiongroup-1.0.4-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pyzmq>=17.0 in c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from circus!=0.17.2,>=0.17.0->bentoml) (19.0.0)\n",
      "Requirement already satisfied: tornado>=5.0.2 in c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from circus!=0.17.2,>=0.17.0->bentoml) (6.0.3)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.1-cp38-cp38-win_amd64.whl (17 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from packaging<22,>=20.0->bentoml) (2.4.6)\n",
      "Collecting pip>=22.2\n",
      "  Using cached pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting build\n",
      "  Using cached build-0.9.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: wheel in c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pip-tools>=6.6.2->bentoml) (0.37.0)\n",
      "Collecting click>=7.0\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from click>=7.0->bentoml) (0.4.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->bentoml) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->bentoml) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->bentoml) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->bentoml) (2.9)\n",
      "Collecting pygments<3.0.0,>=2.6.0\n",
      "  Using cached Pygments-2.13.0-py3-none-any.whl (1.1 MB)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "Collecting anyio>=3.0.0\n",
      "  Using cached anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting charset-normalizer<3.0,>=2.0\n",
      "  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.3-cp38-cp38-win_amd64.whl (28 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.3-cp38-cp38-win_amd64.whl (34 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.8.2-cp38-cp38-win_amd64.whl (56 kB)\n",
      "Requirement already satisfied: six~=1.10 in c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from fs->bentoml) (1.14.0)\n",
      "Collecting appdirs~=1.4.3\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting contextlib2>=0.5.5\n",
      "  Using cached contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from uvicorn->bentoml) (0.9.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from anyio>=3.0.0->watchfiles>=0.15.0->bentoml) (1.1.0)\n",
      "Collecting pep517>=0.9.1\n",
      "  Using cached pep517-0.13.0-py3-none-any.whl (18 kB)\n",
      "Collecting tomli>=1.0.0\n",
      "  Using cached tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: To modify pip, please run the following command:\n",
      "c:\\users\\kumapank\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install bentoml\n"
     ]
    }
   ],
   "source": [
    "!pip install bentoml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZjDPV-5BHZFS"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bentoml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b85cc2581e9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mbentoml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbentoml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mJSON\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bentoml'"
     ]
    }
   ],
   "source": [
    "import bentoml\n",
    "from bentoml.io import JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hQYvq1BwHmpQ"
   },
   "outputs": [],
   "source": [
    "bento_model = bentoml.sklearn.save_model( \"usedcar_prediction_model\", \n",
    "                                         final_model,\n",
    "                                         signatures={\n",
    "                                            \"predict\": {\"batchable\": True, \n",
    "                                                        \"batch_dim\": 0},\n",
    "                                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zujo5dz8HTmz",
    "outputId": "e5510bc8-2979-4b07-ac35-28ec0eee6d42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting service.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile service.py\n",
    "\n",
    "import bentoml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bentoml.io import JSON\n",
    "\n",
    "bento_model = bentoml.sklearn.get(\"usedcar_prediction_model:latest\")\n",
    "\n",
    "model_runner = bento_model.to_runner()\n",
    "\n",
    "svc = bentoml.Service(\"usedcar_price_predictor\", \n",
    "                      runners=[model_runner])\n",
    "\n",
    "\n",
    "@svc.api(input=JSON(), output=JSON())\n",
    "async def predict(input_doc: str):\n",
    "        \n",
    "    df = pd.DataFrame(input_doc, index = [0])\n",
    "    \n",
    "    num_features = ['KM_Driven', 'age', 'power_new',\n",
    "                    'Seats','mileage_new', 'engine_new']    \n",
    "\n",
    "    df[num_features] = df[num_features].apply(pd.to_numeric, \n",
    "                                              errors='coerce')\n",
    "    \n",
    "    print(df.info())\n",
    "    \n",
    "    print(df.head(1))\n",
    "    \n",
    "    predictions = await model_runner.predict.async_run(df)\n",
    "    \n",
    "    return {\"ExpectedSalePrice\": np.round(predictions[0], 2)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1J56W4LZy7f"
   },
   "source": [
    "## Serving the model as service\n",
    "\n",
    "### Starting the service\n",
    "\n",
    "Start the prediction service on port 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qUjSVE5CHI4Z",
    "outputId": "186ad0f3-e649-4938-dbf1-da2759b5fde8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-19T10:16:09+0530 [INFO] [cli] Prometheus metrics for HTTP BentoServer from \"service.py:svc\" can be accessed at http://localhost:5000/metrics.\n",
      "2022-11-19T10:16:11+0530 [INFO] [cli] Starting development HTTP BentoServer from \"service.py:svc\" listening on http://0.0.0.0:5000 (Press CTRL+C to quit)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1 entries, 0 to 0\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   KM_Driven     1 non-null      float64\n",
      " 1   Fuel_Type     1 non-null      object \n",
      " 2   age           1 non-null      float64\n",
      " 3   Transmission  1 non-null      object \n",
      " 4   Owner_Type    1 non-null      object \n",
      " 5   Seats         1 non-null      float64\n",
      " 6   make          1 non-null      object \n",
      " 7   mileage_new   1 non-null      float64\n",
      " 8   engine_new    1 non-null      float64\n",
      " 9   model         1 non-null      object \n",
      " 10  power_new     1 non-null      float64\n",
      " 11  Location      1 non-null      object \n",
      "dtypes: float64(6), object(6)\n",
      "memory usage: 104.0+ bytes\n",
      "None\n",
      "   KM_Driven Fuel_Type  age  ...  model power_new   Location\n",
      "0       10.0    Petrol  4.0  ...  swift      90.0  Bangalore\n",
      "\n",
      "[1 rows x 12 columns]\n",
      "2022-11-19T10:16:17+0530 [INFO] [dev_api_server:usedcar_price_predictor] 127.0.0.1:51273 (scheme=http,method=POST,path=/predict,type=,length=219) (status=200,type=application/json,length=26) 1082.106ms (trace=0ad744c58e9884293683b74fd73c490a,span=69a4f1e7336910b1,sampled=0)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1 entries, 0 to 0\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   KM_Driven     1 non-null      float64\n",
      " 1   Fuel_Type     1 non-null      object \n",
      " 2   age           1 non-null      float64\n",
      " 3   Transmission  1 non-null      object \n",
      " 4   Owner_Type    1 non-null      object \n",
      " 5   Seats         1 non-null      float64\n",
      " 6   make          1 non-null      object \n",
      " 7   mileage_new   1 non-null      float64\n",
      " 8   engine_new    1 non-null      float64\n",
      " 9   model         1 non-null      object \n",
      " 10  power_new     1 non-null      float64\n",
      " 11  Location      1 non-null      object \n",
      "dtypes: float64(6), object(6)\n",
      "memory usage: 104.0+ bytes\n",
      "None\n",
      "   KM_Driven Fuel_Type  age  ...  model power_new   Location\n",
      "0       10.0    Petrol  4.0  ...  swift      90.0  Bangalore\n",
      "\n",
      "[1 rows x 12 columns]\n",
      "2022-11-19T10:17:05+0530 [INFO] [dev_api_server:usedcar_price_predictor] 127.0.0.1:51279 (scheme=http,method=POST,path=/predict,type=,length=243) (status=200,type=application/json,length=26) 563.565ms (trace=f1045db8b3d5b920e37c4b782858312c,span=aa575a12ceaad49e,sampled=0)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!bentoml serve service.py:svc --port=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
