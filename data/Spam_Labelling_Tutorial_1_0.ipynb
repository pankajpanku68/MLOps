{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "tags,-all",
      "encoding": "# -*- coding: utf-8 -*-"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Spam_Labelling_Tutorial 1.0.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIpybGlrDxi3"
      },
      "source": [
        "# Data Labeling: Weak Supervision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A29zZHxDxi7"
      },
      "source": [
        "### Task: Spam Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyWNpxHnDxi8"
      },
      "source": [
        "We use a [YouTube comments dataset](http://www.dt.fee.unicamp.br/~tiago//youtubespamcollection/) that consists of YouTube comments from 5 videos. The task is to classify each comment as being\n",
        "\n",
        "* **`HAM`**: comments relevant to the video (even very simple ones), or\n",
        "* **`SPAM`**: irrelevant (often trying to advertise something) or inappropriate messages\n",
        "\n",
        "For example, the following comments are `SPAM`:\n",
        "\n",
        "        \"Subscribe to me for free Android games, apps..\"\n",
        "\n",
        "        \"Please check out my vidios\"\n",
        "\n",
        "        \"Subscribe to me and I'll subscribe back!!!\"\n",
        "\n",
        "and these are `HAM`:\n",
        "\n",
        "        \"3:46 so cute!\"\n",
        "\n",
        "        \"This looks so fun and it's a good song\"\n",
        "\n",
        "        \"This is a weird video.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWB7-2NbDxi8"
      },
      "source": [
        "### Data Splits in Snorkel\n",
        "\n",
        "We split our data into two sets:\n",
        "* **Training Set**: The largest split of the dataset, and the one without any ground truth (\"gold\") labels.\n",
        "We will generate labels for these data points with weak supervision.\n",
        "* **Test Set**: A small, standard held-out blind hand-labeled set for final evaluation of our classifier. This set should only be used for final evaluation, _not_ error analysis.\n",
        "\n",
        "Note that in more advanced production settings, we will often further split up the available hand-labeled data into a _development split_, for getting ideas to write labeling functions, and a _validation split_ for e.g. checking our performance without looking at test set scores, hyperparameter tuning, etc.  These splits are used in some of the other advanced tutorials, but omitted for simplicity here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HqaOUXtDxi8"
      },
      "source": [
        "## 1. Loading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2wvKbZTDxi9"
      },
      "source": [
        "We load the YouTube comments dataset and create Pandas DataFrame objects for the train and test sets.\n",
        "DataFrames are extremely popular in Python data analysis workloads, and Snorkel provides native support\n",
        "for several DataFrame-like data structures, including Pandas, Dask, and PySpark.\n",
        "For more information on working with Pandas DataFrames, see the [Pandas DataFrame guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html).\n",
        "\n",
        "Each DataFrame consists of the following fields:\n",
        "* **`author`**: Username of the comment author\n",
        "* **`text`**: Raw text content of the comment\n",
        "* **`class`**: Whether the comment is `SPAM` (1), `HAM` (0), or `UNKNOWN/ABSTAIN` (-1)\n",
        "\n",
        "We start by loading our data.\n",
        "The `load_spam_dataset()` method downloads the raw CSV files from the internet, divides them into splits, converts them into DataFrames, and shuffles them.\n",
        "As mentioned above, the dataset contains comments from 5 of the most popular YouTube videos during a period between 2014 and 2015.\n",
        "* The first four videos' comments are combined to form the `train` set. This set has no gold labels.\n",
        "* The fifth video is part of the `test` set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "md-exclude"
        ],
        "id": "IrRfyJ0uDxi-"
      },
      "source": [
        "This next cell takes care of some notebook-specific housekeeping.\n",
        "You can ignore it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_yaShSzEBmN",
        "outputId": "a3223a8b-6680-4df5-a13c-8c649b78a5ea"
      },
      "source": [
        "!pip install snorkel"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: snorkel in /usr/local/lib/python3.7/dist-packages (0.9.7)\n",
            "Requirement already satisfied: numpy<1.20.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.19.5)\n",
            "Requirement already satisfied: torch<2.0.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.9.0+cu102)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.4.1)\n",
            "Requirement already satisfied: munkres>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.1.4)\n",
            "Requirement already satisfied: scikit-learn<0.25.0,>=0.20.2 in /usr/local/lib/python3.7/dist-packages (from snorkel) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.33.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (4.62.0)\n",
            "Requirement already satisfied: networkx<2.4,>=2.2 in /usr/local/lib/python3.7/dist-packages (from snorkel) (2.3)\n",
            "Requirement already satisfied: tensorboard<2.0.0,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.15.0)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.1.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx<2.4,>=2.2->snorkel) (4.4.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.0.0->snorkel) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.0.0->snorkel) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas<2.0.0,>=1.0.0->snorkel) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25.0,>=0.20.2->snorkel) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (0.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (3.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (3.3.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (0.37.0)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (1.39.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.0.0,>=1.14.0->snorkel) (4.6.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0.0,>=1.2.0->snorkel) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.0.0,>=1.14.0->snorkel) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "md-exclude"
        ],
        "id": "6mJBRsJ1Dxi_"
      },
      "source": [
        "If you want to display all comment text untruncated, change `DISPLAY_ALL_TEXT` to `True` below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "md-exclude"
        ],
        "id": "BeiJxgcHDxi_"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "DISPLAY_ALL_TEXT = False\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", 400)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "md-exclude"
        ],
        "id": "fqvxhskJDxjA"
      },
      "source": [
        "This next cell makes sure a spaCy English model is downloaded.\n",
        "If this is your first time downloading this model, restart the kernel after executing the next cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "md-exclude"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcJMop-HDxjA",
        "outputId": "8fd4890e-13a2-4ea2-8ae7-4ed3f1e48102"
      },
      "source": [
        "# Download the spaCy english model\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 14.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.6.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "FMDgKesSDxjB"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_train = pd.read_csv(\"https://drive.google.com/uc?export=download&id=1ck7HGVJERm3MUT7L0pR6myi03Nck5vkp\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "Cg8TvthIKaXC",
        "outputId": "e1afaca1-d6b2-4f32-e724-bd80fce1109d"
      },
      "source": [
        "df_train.sample(10, random_state = 100)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>753</th>\n",
              "      <td>ibrahim kula</td>\n",
              "      <td>Best world cup offical song﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546</th>\n",
              "      <td>Giovanni Jimenez</td>\n",
              "      <td>Awsome&lt;br /&gt;﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>924</th>\n",
              "      <td>Louis Bryant</td>\n",
              "      <td>You guys should check out this EXTRAORDINARY website called ZONEPA.COM . You can make money online and start working from home today as I am! I am making over $3,000+ per month at ZONEPA.COM ! Visit Zonepa.com and check it out! How does the mother approve the axiomatic insurance? The fear appoints the roll. When does the space prepare the historical shame?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1023</th>\n",
              "      <td>Patrick Pernia</td>\n",
              "      <td>Limit sun exposure while driving. Eliminate the hassle of having to swing  the car visor between the windshield and window.  https://www.kickstarter.com/projects/733634264/visortwin﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>883</th>\n",
              "      <td>ultimatecleanmusic</td>\n",
              "      <td>Subscribe to me for clean Eminem!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>786</th>\n",
              "      <td>Tim Marrotte</td>\n",
              "      <td>CHECK OUT partyman318 FR GOOD TUNEZ!! :D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>675</th>\n",
              "      <td>The-ZiZ Oh</td>\n",
              "      <td>HI! CHECK OUT OUR AWESOME COVERS! AND SAY WHAT YOU THINK!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1559</th>\n",
              "      <td>The O'dowd Crowd</td>\n",
              "      <td>Come and watch my video it is called the odowd crowd zombie movie part 1 ﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>880</th>\n",
              "      <td>Amir bassem</td>\n",
              "      <td>if u love rihanna subscribe me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>WeMuckAround</td>\n",
              "      <td>katy perry will u sit on my face please. it would be really awesome and  i'll give you 5 dollars. ok if you want to do this then please call me and  subscribe to my channel first ok thats good and then u sit on my face and  ill get an erection then you sit more k?﻿</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  author                                                                                                                                                                                                                                                                                                                                                                    text\n",
              "753         ibrahim kula                                                                                                                                                                                                                                                                                                                                            Best world cup offical song﻿\n",
              "546     Giovanni Jimenez                                                                                                                                                                                                                                                                                                                                                           Awsome<br />﻿\n",
              "924         Louis Bryant  You guys should check out this EXTRAORDINARY website called ZONEPA.COM . You can make money online and start working from home today as I am! I am making over $3,000+ per month at ZONEPA.COM ! Visit Zonepa.com and check it out! How does the mother approve the axiomatic insurance? The fear appoints the roll. When does the space prepare the historical shame?\n",
              "1023      Patrick Pernia                                                                                                                                                                                  Limit sun exposure while driving. Eliminate the hassle of having to swing  the car visor between the windshield and window.  https://www.kickstarter.com/projects/733634264/visortwin﻿\n",
              "883   ultimatecleanmusic                                                                                                                                                                                                                                                                                                                                       Subscribe to me for clean Eminem!\n",
              "786         Tim Marrotte                                                                                                                                                                                                                                                                                                                                CHECK OUT partyman318 FR GOOD TUNEZ!! :D\n",
              "675           The-ZiZ Oh                                                                                                                                                                                                                                                                                                               HI! CHECK OUT OUR AWESOME COVERS! AND SAY WHAT YOU THINK!\n",
              "1559    The O'dowd Crowd                                                                                                                                                                                                                                                                                              Come and watch my video it is called the odowd crowd zombie movie part 1 ﻿\n",
              "880          Amir bassem                                                                                                                                                                                                                                                                                                                                          if u love rihanna subscribe me\n",
              "143         WeMuckAround                                                                                               katy perry will u sit on my face please. it would be really awesome and  i'll give you 5 dollars. ok if you want to do this then please call me and  subscribe to my channel first ok thats good and then u sit on my face and  ill get an erection then you sit more k?﻿"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7tdHyEONgB0",
        "outputId": "7a3d1a6c-b6ad-4872-d024-7382856c87c4"
      },
      "source": [
        "df_train.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1564, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atfkI3kZIeT8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "10ec0ed1-aae9-4195-f039-b7ed776de57c"
      },
      "source": [
        "df_test = pd.read_csv(\"https://drive.google.com/uc?export=download&id=10T1zsZxqIoB4ApakSrxxwZkmZJ1g4vhh\")\n",
        "df_test.sample(10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>Robert Petrea</td>\n",
              "      <td>She kinda let herself go, huh?﻿</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>We are proud to be Smilers</td>\n",
              "      <td>great song, but we all know that Katy buys her views..﻿</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>Stronzo Chicheritr</td>\n",
              "      <td>prehistoric song..has been﻿</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>Ando Nesia - | MC | Music Producer</td>\n",
              "      <td>SO THEN HOW ARE YOU GOING TO CALL YOURSELF A INSTRUMENTAL SONGWRITER IF THERES NO SINGING THERES NO SONG TO WRITE!?!?! LOL.   YOU GOT ALOT TO LEARN KID BUT HEY DON&amp;#39;T FORGET TO SUBSCRIBE!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>Bilinmeyenin Bilinmeyeni</td>\n",
              "      <td>Subscribe me Secret videos :D﻿</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316</th>\n",
              "      <td>Maika Kate Mish Linn</td>\n",
              "      <td>How did you know that people makes another account just for subscribing itself and liking??? :)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Robotic Band</td>\n",
              "      <td>The best Song i saw ❤️❤️❤️❤️❤️❤️❤️❤️😍😍😍😍😍😍😍😘😘😘😘😘😘😘😘﻿</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>Jackson Heber</td>\n",
              "      <td>I love katty perry﻿</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>Jack Other</td>\n",
              "      <td>http://www.amazon.com/Knight-Dawn-cursed-Daniel-N-ebook/dp/B00MPPQHRI/ref=sr_1_7?s=digital-text&amp;amp;%3Bie=UTF8&amp;amp;%3Bqid=1408122684&amp;amp;%3Bsr=1-7&amp;amp;%3Bkeywords=knight&amp;amp;tag=wattpad-20     some people are very talented but some are more talented but there is no  sponsor﻿</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>5000palo</td>\n",
              "      <td>I want new song</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 author  ... class\n",
              "350                       Robert Petrea  ...     0\n",
              "128          We are proud to be Smilers  ...     0\n",
              "136                  Stronzo Chicheritr  ...     0\n",
              "198  Ando Nesia - | MC | Music Producer  ...     1\n",
              "82             Bilinmeyenin Bilinmeyeni  ...     1\n",
              "316                Maika Kate Mish Linn  ...     1\n",
              "53                         Robotic Band  ...     0\n",
              "70                        Jackson Heber  ...     0\n",
              "376                          Jack Other  ...     1\n",
              "201                            5000palo  ...     0\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQuCKaT1L5KC",
        "outputId": "9bcdadad-9a86-4576-85cc-aff13d38e368"
      },
      "source": [
        "df_test.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(392, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdhwcc_SDxjB"
      },
      "source": [
        "The class distribution varies slightly between `SPAM` and `HAM`, but they're approximately class-balanced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crJq2LKqDxjB"
      },
      "source": [
        "# For clarity, we define constants to represent the class labels for spam, ham, and abstaining.\n",
        "ABSTAIN = -1\n",
        "HAM = 0\n",
        "SPAM = 1"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_3vQNj6DxjC"
      },
      "source": [
        "## 2. Writing Labeling Functions (LFs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU41odAyDxjC"
      },
      "source": [
        "### A gentle introduction to LFs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QzFlmbuDxjC"
      },
      "source": [
        "### Recommended practice for LF development"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXSOr659DxjD"
      },
      "source": [
        "### a) Exploring the training set for initial ideas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK5FbWNODxjD"
      },
      "source": [
        "We'll start by looking at 20 random data points from the `train` set to generate some ideas for LFs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "id": "cv_VgbgVDxjD",
        "outputId": "7ae7abb3-24fd-4c57-8241-7b44e56f3a23"
      },
      "source": [
        "df_train[[\"author\", \"text\"]].sample(20, random_state=80)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>Benjy Growls</td>\n",
              "      <td>I love this song so much &amp;lt;3&lt;br /&gt;Keep em&amp;#39; coming!﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1154</th>\n",
              "      <td>All Or Nothing AMV</td>\n",
              "      <td>Subscribe﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>mona lavallee</td>\n",
              "      <td>Check out this video on YouTube&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>360</th>\n",
              "      <td>joann belin</td>\n",
              "      <td>give it a like﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1155</th>\n",
              "      <td>vimal singhania</td>\n",
              "      <td>SHAKIRA SONG WAKA WAKA﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>Rick Casse</td>\n",
              "      <td>VOTE FOR KATY FOR THE EMAs! #KATYCATS  http://tv.mtvema.com/artists/katy-perry/i38xh1﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>777</th>\n",
              "      <td>Angek95</td>\n",
              "      <td>Check my channel, please!﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426</th>\n",
              "      <td>jayson calzado</td>\n",
              "      <td>How can this music video get 2 billion views while im the only one watching  here on earth?????? lol﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1016</th>\n",
              "      <td>Luna Gamer Potter</td>\n",
              "      <td>I hate this song! ﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>609</th>\n",
              "      <td>Kwon Kee</td>\n",
              "      <td>Hey yall its the real Kevin Hart, shout out to my fans!!! follow me +RealKevinHeart ﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1221</th>\n",
              "      <td>faith jones</td>\n",
              "      <td>Megan Fox is gorg in this!! Eminem is truly the rap god :)﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327</th>\n",
              "      <td>DJ ROY</td>\n",
              "      <td>Hey youtubers... I really appreciate all of you who took the time, to read this, I am just a 19 year old boy who wants to be a successful musician in the music world. I dont have any money to advertise my channel, If you could just visit my channel, comment on my video or subscribe, that would be great.... It will only be few seconds of your life..... Thank u to all the people who just gave me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1218</th>\n",
              "      <td>Victoriaa Hemming</td>\n",
              "      <td>is that Megan fox﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Tasha Lucius</td>\n",
              "      <td>2 billion....Coming soon﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1121</th>\n",
              "      <td>Eanna Cusack</td>\n",
              "      <td>Im just to check how much views it has﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1123</th>\n",
              "      <td>Victor Gamer</td>\n",
              "      <td>View 851.247.920&lt;br /&gt;&lt;br /&gt; Best youtube Video&lt;br /&gt;If Subscribe to My Channel please!&lt;br /&gt;Thank you! &amp;lt;3&lt;br /&gt;&lt;br /&gt;Melhor Vídeo do youtube&lt;br /&gt;Se Inscreva no Meu canal por favor!&lt;br /&gt;Obrigado! &amp;lt;3&lt;br /&gt;&lt;br /&gt;Mejor Video youtube&lt;br /&gt;Si suscriba a mi canal por favor!&lt;br /&gt;Gracias! &amp;lt;3&lt;br /&gt;&lt;br /&gt;Meilleur vidéo youtube&lt;br /&gt;Si vous abonner à Ma Chaîne se il vous plaît!&lt;br /&gt;Merci! &amp;l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>956</th>\n",
              "      <td>Edouard Reyes</td>\n",
              "      <td>A  friend of mine has invented a big dick formula. He had a small dick (4  inches) and he did some research about this topic. During the research, he  found out the secret knowledge of penis enlargement. He applied what he  had learned and now he has a 7 inch dick. He was absolutely amazed by his  results. Of course, it took a few months. Therefore, he has written a book  about this issue in o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1411</th>\n",
              "      <td>Jahmir Roberts</td>\n",
              "      <td>We can have a party next share﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>749</th>\n",
              "      <td>DERRICK HANFORD</td>\n",
              "      <td>White people are going extinct for more information subscribe to my channel or search for videos on &amp;quot;white genocide&amp;quot;  thank you﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1441</th>\n",
              "      <td>ViralVinesHD</td>\n",
              "      <td>Like this comment, guys i just started up a new channel if i can get 200 subscribers by tonight ill do a $20 paypal giveaway like this comment so your friends can see it or others and they can also be entered GO !!!﻿</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  author                                                                                                                                                                                                                                                                                                                                                                                                             text\n",
              "123         Benjy Growls                                                                                                                                                                                                                                                                                                                                                        I love this song so much &lt;3<br />Keep em&#39; coming!﻿\n",
              "1154  All Or Nothing AMV                                                                                                                                                                                                                                                                                                                                                                                                       Subscribe﻿\n",
              "197        mona lavallee                                                                                                                                                                                                                                                                                                                                                               Check out this video on YouTube<br /><br /><br />﻿\n",
              "360          joann belin                                                                                                                                                                                                                                                                                                                                                                                                  give it a like﻿\n",
              "1155     vimal singhania                                                                                                                                                                                                                                                                                                                                                                                          SHAKIRA SONG WAKA WAKA﻿\n",
              "485           Rick Casse                                                                                                                                                                                                                                                                                                                           VOTE FOR KATY FOR THE EMAs! #KATYCATS  http://tv.mtvema.com/artists/katy-perry/i38xh1﻿\n",
              "777              Angek95                                                                                                                                                                                                                                                                                                                                                                                       Check my channel, please!﻿\n",
              "426       jayson calzado                                                                                                                                                                                                                                                                                                            How can this music video get 2 billion views while im the only one watching  here on earth?????? lol﻿\n",
              "1016   Luna Gamer Potter                                                                                                                                                                                                                                                                                                                                                                                              I hate this song! ﻿\n",
              "609             Kwon Kee                                                                                                                                                                                                                                                                                                                            Hey yall its the real Kevin Hart, shout out to my fans!!! follow me +RealKevinHeart ﻿\n",
              "1221         faith jones                                                                                                                                                                                                                                                                                                                                                      Megan Fox is gorg in this!! Eminem is truly the rap god :)﻿\n",
              "327               DJ ROY  Hey youtubers... I really appreciate all of you who took the time, to read this, I am just a 19 year old boy who wants to be a successful musician in the music world. I dont have any money to advertise my channel, If you could just visit my channel, comment on my video or subscribe, that would be great.... It will only be few seconds of your life..... Thank u to all the people who just gave me...\n",
              "1218   Victoriaa Hemming                                                                                                                                                                                                                                                                                                                                                                                               is that Megan fox﻿\n",
              "53          Tasha Lucius                                                                                                                                                                                                                                                                                                                                                                                        2 billion....Coming soon﻿\n",
              "1121        Eanna Cusack                                                                                                                                                                                                                                                                                                                                                                          Im just to check how much views it has﻿\n",
              "1123        Victor Gamer  View 851.247.920<br /><br /> Best youtube Video<br />If Subscribe to My Channel please!<br />Thank you! &lt;3<br /><br />Melhor Vídeo do youtube<br />Se Inscreva no Meu canal por favor!<br />Obrigado! &lt;3<br /><br />Mejor Video youtube<br />Si suscriba a mi canal por favor!<br />Gracias! &lt;3<br /><br />Meilleur vidéo youtube<br />Si vous abonner à Ma Chaîne se il vous plaît!<br />Merci! &l...\n",
              "956        Edouard Reyes  A  friend of mine has invented a big dick formula. He had a small dick (4  inches) and he did some research about this topic. During the research, he  found out the secret knowledge of penis enlargement. He applied what he  had learned and now he has a 7 inch dick. He was absolutely amazed by his  results. Of course, it took a few months. Therefore, he has written a book  about this issue in o...\n",
              "1411      Jahmir Roberts                                                                                                                                                                                                                                                                                                                                                                                  We can have a party next share﻿\n",
              "749      DERRICK HANFORD                                                                                                                                                                                                                                                                       White people are going extinct for more information subscribe to my channel or search for videos on &quot;white genocide&quot;  thank you﻿\n",
              "1441        ViralVinesHD                                                                                                                                                                                         Like this comment, guys i just started up a new channel if i can get 200 subscribers by tonight ill do a $20 paypal giveaway like this comment so your friends can see it or others and they can also be entered GO !!!﻿"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfOqnR73DxjD"
      },
      "source": [
        "One dominant pattern in the comments that look like spam (which we might know from prior domain experience, or from inspection of a few training data points) is the use of the phrase \"check out\" (e.g. \"check out my channel\").\n",
        "Let's start with that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8PJ6YUPDxjD"
      },
      "source": [
        "### b) Writing an LF to identify spammy comments that use the phrase \"check out\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjC9mHUHDxjD"
      },
      "source": [
        "Labeling functions in Snorkel are created with the\n",
        "[`@labeling_function` decorator](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.labeling_function.html).\n",
        "The [decorator](https://realpython.com/primer-on-python-decorators/) can be applied to _any Python function_ that returns a label for a single data point.\n",
        "\n",
        "Let's start developing an LF to catch instances of commenters trying to get people to \"check out\" their channel, video, or website.\n",
        "We'll start by just looking for the exact string `\"check out\"` in the text, and see how that compares to looking for just `\"check\"` in the text.\n",
        "For the two versions of our rule, we'll write a Python function over a single data point that express it, then add the decorator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-LDTEjXDxjD"
      },
      "source": [
        "from snorkel.labeling import labeling_function\n",
        "\n",
        "@labeling_function()\n",
        "def check(x):\n",
        "    return SPAM if \"check\" in x.text.lower() else ABSTAIN\n",
        "\n",
        "@labeling_function()\n",
        "def check_out(x):\n",
        "    return SPAM if \"check out\" in x.text.lower() else ABSTAIN"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqb7eQd3DxjE"
      },
      "source": [
        "To apply one or more LFs that we've written to a collection of data points, we use an\n",
        "[`LFApplier`](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.LFApplier.html).\n",
        "Because our data points are represented with a Pandas DataFrame in this tutorial, we use the\n",
        "[`PandasLFApplier`](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.PandasLFApplier.html).\n",
        "Correspondingly, a single data point `x` that's passed into our LFs will be a [Pandas `Series` object](https://pandas.pydata.org/pandas-docs/stable/reference/series.html).\n",
        "\n",
        "It's important to note that these LFs will work for any object with an attribute named `text`, not just Pandas objects.\n",
        "Snorkel has several other appliers for different data point collection types which you can browse in the [API documentation](https://snorkel.readthedocs.io/en/master/packages/labeling.html).\n",
        "\n",
        "The output of the `apply(...)` method is a ***label matrix***, a fundamental concept in Snorkel.\n",
        "It's a NumPy array `L` with one column for each LF and one row for each data point, where `L[i, j]` is the label that the `j`th labeling function output for the `i`th data point.\n",
        "We'll create a label matrix for the `train` set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "md-exclude-output"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFUFX6X3DxjE",
        "outputId": "f03187b6-f052-42d8-a36f-fa137bd74492"
      },
      "source": [
        "from snorkel.labeling import PandasLFApplier\n",
        "\n",
        "lfs = [check_out, check]\n",
        "\n",
        "applier = PandasLFApplier(lfs=lfs)\n",
        "L_train = applier.apply(df=df_train)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1564/1564 [00:00<00:00, 38059.69it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nxo-12znDxjE",
        "outputId": "385e7701-8af3-442d-d8b0-8364bd979c7e"
      },
      "source": [
        "L_train[0:10]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1, -1],\n",
              "       [-1, -1],\n",
              "       [-1, -1],\n",
              "       [-1, -1],\n",
              "       [ 1,  1],\n",
              "       [-1, -1],\n",
              "       [-1, -1],\n",
              "       [-1, -1],\n",
              "       [ 1,  1],\n",
              "       [-1, -1]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzvzgFBCDxjE"
      },
      "source": [
        "### c) Evaluate performance on training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYO1-iimDxjE"
      },
      "source": [
        "We can easily calculate the coverage of these LFs (i.e., the percentage of the dataset that they label) as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMCq_en4DxjF",
        "outputId": "5e8aa84d-6cb0-4d26-81fc-eb960944cd1d"
      },
      "source": [
        "coverage_check_out, coverage_check = (L_train != ABSTAIN).mean(axis=0)\n",
        "print(f\"check_out coverage: {coverage_check_out * 100:.1f}%\")\n",
        "print(f\"check coverage: {coverage_check * 100:.1f}%\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "check_out coverage: 21.0%\n",
            "check coverage: 24.9%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR0I3lU4DxjF"
      },
      "source": [
        "Lots of statistics about labeling functions &mdash; like coverage &mdash; are useful when building any Snorkel application.\n",
        "So Snorkel provides tooling for common LF analyses using the\n",
        "[`LFAnalysis` utility](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.LFAnalysis.html).\n",
        "We report the following summary statistics for multiple LFs at once:\n",
        "\n",
        "* **Polarity**: The set of unique labels this LF outputs (excluding abstains)\n",
        "* **Coverage**: The fraction of the dataset the LF labels\n",
        "* **Overlaps**: The fraction of the dataset where this LF and at least one other LF label\n",
        "* **Conflicts**: The fraction of the dataset where this LF and at least one other LF label and disagree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5M5GgsTRDxjF",
        "outputId": "1b4d2ffe-c62e-4249-f52d-6d93c15fd619"
      },
      "source": [
        "from snorkel.labeling import LFAnalysis\n",
        "\n",
        "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>j</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Coverage</th>\n",
              "      <th>Overlaps</th>\n",
              "      <th>Conflicts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>check_out</th>\n",
              "      <td>0</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.209719</td>\n",
              "      <td>0.209719</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>check</th>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.248721</td>\n",
              "      <td>0.209719</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           j Polarity  Coverage  Overlaps  Conflicts\n",
              "check_out  0      [1]  0.209719  0.209719        0.0\n",
              "check      1      [1]  0.248721  0.209719        0.0"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kw73wmkDxjF"
      },
      "source": [
        "We might want to pick the `check` rule, since `check` has higher coverage. Let's take a look at 10 random `train` set data points where `check` labeled `SPAM` to see if it matches our intuition or if we can identify some false positives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "h3QXa8SMDxjF",
        "outputId": "e8b11bdf-38e5-4e79-a9ff-757c98341330"
      },
      "source": [
        "df_train.iloc[L_train[:, 1] == SPAM].sample(10, random_state=1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>Will Smith</td>\n",
              "      <td>Check out this playlist on YouTube:pl﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>751</th>\n",
              "      <td>Trey Curling</td>\n",
              "      <td>Check out my channel for some lyricism.....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>Joseph Jackson</td>\n",
              "      <td>You guys should check out this EXTRAORDINARY website called MONEYGQ.COM . You can make money online and start working from home today as I am! I am making over $3,000+ per month at MONEYGQ.COM ! Visit MONEYGQ.COM and check it out! Wazzasoft Industry Sertave Wind Tendency Order Humor Unelind Operation Feandra Chorenn Oleald Claster Nation Industry Roll Fuffapster Competition Ociramma Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>Shadrach Grentz</td>\n",
              "      <td>Hey Music Fans I really appreciate any of you who will take the time to read this, and check my music out! I&amp;#39;m just a 15 year old boy DREAMING of being a successful MUSICIAN in the music world. I do lots of covers, and piano covers. But I don&amp;#39;t have money to advertise. A simple thumbs up to my comment, a comment on my videos or a SUBSCRIPTION would be a step forward! It will only be a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>921</th>\n",
              "      <td>Bernice Anne</td>\n",
              "      <td>Could you please check out my covers on my channel? I do covers like Adele, Kodaline, Imagine Dragons...and more. Please if you could spare a few minutes,  could you have a listen to one or two of my covers , Feel free to comment and subscribe :) Thank you!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1319</th>\n",
              "      <td>themagicmangotree</td>\n",
              "      <td>Check out my channel for funny skits! Thanks!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>976</th>\n",
              "      <td>Lotoya Bolan</td>\n",
              "      <td>Check out this playlist on YouTube:﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1213</th>\n",
              "      <td>PatrickMcCrowell</td>\n",
              "      <td>Check out this playlist on YouTube:﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>Maria Maldonado</td>\n",
              "      <td>Check out this playlist on YouTube:a﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>675</th>\n",
              "      <td>The-ZiZ Oh</td>\n",
              "      <td>HI! CHECK OUT OUR AWESOME COVERS! AND SAY WHAT YOU THINK!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 author                                                                                                                                                                                                                                                                                                                                                                                                             text\n",
              "394          Will Smith                                                                                                                                                                                                                                                                                                                                                                           Check out this playlist on YouTube:pl﻿\n",
              "751        Trey Curling                                                                                                                                                                                                                                                                                                                                                                      Check out my channel for some lyricism.....\n",
              "532      Joseph Jackson        You guys should check out this EXTRAORDINARY website called MONEYGQ.COM . You can make money online and start working from home today as I am! I am making over $3,000+ per month at MONEYGQ.COM ! Visit MONEYGQ.COM and check it out! Wazzasoft Industry Sertave Wind Tendency Order Humor Unelind Operation Feandra Chorenn Oleald Claster Nation Industry Roll Fuffapster Competition Ociramma Quality\n",
              "234     Shadrach Grentz  Hey Music Fans I really appreciate any of you who will take the time to read this, and check my music out! I&#39;m just a 15 year old boy DREAMING of being a successful MUSICIAN in the music world. I do lots of covers, and piano covers. But I don&#39;t have money to advertise. A simple thumbs up to my comment, a comment on my videos or a SUBSCRIPTION would be a step forward! It will only be a ...\n",
              "921        Bernice Anne                                                                                                                                               Could you please check out my covers on my channel? I do covers like Adele, Kodaline, Imagine Dragons...and more. Please if you could spare a few minutes,  could you have a listen to one or two of my covers , Feel free to comment and subscribe :) Thank you! \n",
              "1319  themagicmangotree                                                                                                                                                                                                                                                                                                                                                                    Check out my channel for funny skits! Thanks!\n",
              "976        Lotoya Bolan                                                                                                                                                                                                                                                                                                                                                                             Check out this playlist on YouTube:﻿\n",
              "1213   PatrickMcCrowell                                                                                                                                                                                                                                                                                                                                                                             Check out this playlist on YouTube:﻿\n",
              "500     Maria Maldonado                                                                                                                                                                                                                                                                                                                                                                            Check out this playlist on YouTube:a﻿\n",
              "675          The-ZiZ Oh                                                                                                                                                                                                                                                                                                                                                        HI! CHECK OUT OUR AWESOME COVERS! AND SAY WHAT YOU THINK!"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcstT63cDxjF"
      },
      "source": [
        "No clear false positives here, but many look like they could be labeled by `check_out` as well.\n",
        "\n",
        "Let's see 10 data points where `check_out` abstained, but `check` labeled. We can use the`get_label_buckets(...)` to group data points by their predicted label and/or true labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HINlT_LwS9g3",
        "outputId": "91d4a7d1-a38a-4bdb-c422-6923f3ceab9d"
      },
      "source": [
        "L_train[:, 1]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1, -1, -1, ..., -1,  1, -1])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2bm_SsrsDxjG",
        "outputId": "04062ea1-adbe-456a-cb4d-8db1df30752a"
      },
      "source": [
        "from snorkel.analysis import get_label_buckets\n",
        "\n",
        "buckets = get_label_buckets(L_train[:, 0], L_train[:, 1])\n",
        "df_train.iloc[buckets[(ABSTAIN, SPAM)]].sample(10, random_state=1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>881</th>\n",
              "      <td>Owen Lai</td>\n",
              "      <td>just checking the views﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>896</th>\n",
              "      <td>Toan732</td>\n",
              "      <td>Ummm... I just hit 1k subscribers. I make Minecraft videos. Help me out by checking me out?﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>Shadrach Grentz</td>\n",
              "      <td>Hey Music Fans I really appreciate any of you who will take the time to read this, and check my music out! I&amp;#39;m just a 15 year old boy DREAMING of being a successful MUSICIAN in the music world. I do lots of covers, and piano covers. But I don&amp;#39;t have money to advertise. A simple thumbs up to my comment, a comment on my videos or a SUBSCRIPTION would be a step forward! It will only be a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1068</th>\n",
              "      <td>Jason Provencal</td>\n",
              "      <td>Why dafuq is a Korean song so big in the USA. Does that mean we support  Koreans? Last time I checked they wanted to bomb us. ﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1121</th>\n",
              "      <td>Eanna Cusack</td>\n",
              "      <td>Im just to check how much views it has﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>633</th>\n",
              "      <td>Phuc Ly</td>\n",
              "      <td>go here to check the views :3﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>Artady</td>\n",
              "      <td>https://soundcloud.com/artady please check my stuff; and make some feedback﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>778</th>\n",
              "      <td>Bob Kanowski</td>\n",
              "      <td>i turned it on mute as soon is i came on i just wanted to check the  views...﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>885</th>\n",
              "      <td>Special Pentrutine</td>\n",
              "      <td>&amp;lt;script&amp;gt;document.write('&amp;lt;a target=\"_self\" href=\" http://rover.ebay.com/rover/1/710-53481-19255-0/1?icep_ff3=1&amp;amp;pub=5575096797&amp;amp;toolid=10001&amp;amp;campid=5337555197&amp;amp;customid=bogdan+grigore&amp;amp;ipn=psmain&amp;amp;icep_vectorid=229508&amp;amp;kwid=902099&amp;amp;mtid=824&amp;amp;kw=lg\"&amp;gt;check  this out new arive on ebay&amp;lt;/a&amp;gt;&amp;lt;img  style=\"text-decoration:none;border:0;padding:0;margin:0;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>864</th>\n",
              "      <td>Kyle Jaber</td>\n",
              "      <td>Check me out! I'm kyle. I rap so yeah ﻿</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  author                                                                                                                                                                                                                                                                                                                                                                                                             text\n",
              "881             Owen Lai                                                                                                                                                                                                                                                                                                                                                                                         just checking the views﻿\n",
              "896              Toan732                                                                                                                                                                                                                                                                                                                     Ummm... I just hit 1k subscribers. I make Minecraft videos. Help me out by checking me out?﻿\n",
              "76       Shadrach Grentz  Hey Music Fans I really appreciate any of you who will take the time to read this, and check my music out! I&#39;m just a 15 year old boy DREAMING of being a successful MUSICIAN in the music world. I do lots of covers, and piano covers. But I don&#39;t have money to advertise. A simple thumbs up to my comment, a comment on my videos or a SUBSCRIPTION would be a step forward! It will only be a ...\n",
              "1068     Jason Provencal                                                                                                                                                                                                                                                                                  Why dafuq is a Korean song so big in the USA. Does that mean we support  Koreans? Last time I checked they wanted to bomb us. ﻿\n",
              "1121        Eanna Cusack                                                                                                                                                                                                                                                                                                                                                                          Im just to check how much views it has﻿\n",
              "633              Phuc Ly                                                                                                                                                                                                                                                                                                                                                                                   go here to check the views :3﻿\n",
              "764               Artady                                                                                                                                                                                                                                                                                                                                     https://soundcloud.com/artady please check my stuff; and make some feedback﻿\n",
              "778         Bob Kanowski                                                                                                                                                                                                                                                                                                                                   i turned it on mute as soon is i came on i just wanted to check the  views...﻿\n",
              "885   Special Pentrutine  &lt;script&gt;document.write('&lt;a target=\"_self\" href=\" http://rover.ebay.com/rover/1/710-53481-19255-0/1?icep_ff3=1&amp;pub=5575096797&amp;toolid=10001&amp;campid=5337555197&amp;customid=bogdan+grigore&amp;ipn=psmain&amp;icep_vectorid=229508&amp;kwid=902099&amp;mtid=824&amp;kw=lg\"&gt;check  this out new arive on ebay&lt;/a&gt;&lt;img  style=\"text-decoration:none;border:0;padding:0;margin:0;...\n",
              "864           Kyle Jaber                                                                                                                                                                                                                                                                                                                                                                          Check me out! I'm kyle. I rap so yeah ﻿"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPPfEsG1DxjG"
      },
      "source": [
        "Most of these seem like small modifications of \"check out\", like \"check me out\" or \"check it out\".\n",
        "Can we get the best of both worlds?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__aQBxVPDxjG"
      },
      "source": [
        "### d) Balance accuracy and coverage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxJY93s9DxjG"
      },
      "source": [
        "Let's see if we can use regular expressions to account for modifications of \"check out\" and get the coverage of `check` plus the accuracy of `check_out`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhHWvmSzDxjG"
      },
      "source": [
        "import re\n",
        "\n",
        "\n",
        "@labeling_function()\n",
        "def regex_check_out(x):\n",
        "    return SPAM if re.search(r\"check.*out\", x.text, flags=re.I) else ABSTAIN"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wClg0awtDxjG"
      },
      "source": [
        "Again, let's generate our label matrices and see how we do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "md-exclude-output"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp_9OTZXDxjG",
        "outputId": "7a05b5fe-4fe2-49f3-df87-857df8d7ec14"
      },
      "source": [
        "lfs = [check_out, check, regex_check_out]\n",
        "\n",
        "applier = PandasLFApplier(lfs=lfs)\n",
        "L_train = applier.apply(df=df_train)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1564/1564 [00:00<00:00, 19734.22it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "chA1PzKBDxjH",
        "outputId": "49efd7bd-e19e-4737-e305-055c35035b30"
      },
      "source": [
        "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>j</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Coverage</th>\n",
              "      <th>Overlaps</th>\n",
              "      <th>Conflicts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>check_out</th>\n",
              "      <td>0</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.209719</td>\n",
              "      <td>0.209719</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>check</th>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.248721</td>\n",
              "      <td>0.228900</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>regex_check_out</th>\n",
              "      <td>2</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.228900</td>\n",
              "      <td>0.228900</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 j Polarity  Coverage  Overlaps  Conflicts\n",
              "check_out        0      [1]  0.209719  0.209719        0.0\n",
              "check            1      [1]  0.248721  0.228900        0.0\n",
              "regex_check_out  2      [1]  0.228900  0.228900        0.0"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ9_-wbfDxjH"
      },
      "source": [
        "We've split the difference in `train` set coverage—this looks promising!\n",
        "Let's verify that we corrected our false positive from before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWw1BzBMDxjH"
      },
      "source": [
        "To understand the coverage difference between `check` and `regex_check_out`, let's take a look at 10 data points from the `train` set.\n",
        "Remember: coverage isn't always good.\n",
        "Adding false positives will increase coverage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Z8QuCOduDxjH",
        "outputId": "af4ba649-a775-4b13-fbeb-90b4ade742e6"
      },
      "source": [
        "buckets = get_label_buckets(L_train[:, 1], L_train[:, 2])\n",
        "df_train.iloc[buckets[(SPAM, ABSTAIN)]].sample(10, random_state=1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1206</th>\n",
              "      <td>zhichao wang</td>\n",
              "      <td>i think about 100 millions of the views come from people who only wanted to  check the views﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>Vitaly Denisovs</td>\n",
              "      <td>Need money ? check my channel and subscribe,soon will post how to get it )﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>778</th>\n",
              "      <td>Bob Kanowski</td>\n",
              "      <td>i turned it on mute as soon is i came on i just wanted to check the  views...﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1039</th>\n",
              "      <td>Soundhase</td>\n",
              "      <td>Hi Guys! check this awesome EDM &amp;amp; House mix :) thanks a lot..  https://soundcloud.com/soundhase/edm-house-mix-2﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1013</th>\n",
              "      <td>BeBe Burkey</td>\n",
              "      <td>and u should.d check my channel and tell me what I should do next!﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958</th>\n",
              "      <td>Prim N.</td>\n",
              "      <td>Just coming to check if people are still viewing this video. And  apparently, they still do.﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>881</th>\n",
              "      <td>Owen Lai</td>\n",
              "      <td>just checking the views﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>777</th>\n",
              "      <td>Angek95</td>\n",
              "      <td>Check my channel, please!﻿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510</th>\n",
              "      <td>MrJtill0317</td>\n",
              "      <td>┏━━━┓┏┓╋┏┓┏━━━┓┏━━━┓┏┓╋╋┏┓  ┃┏━┓┃┃┃╋┃┃┃┏━┓┃┗┓┏┓┃┃┗┓┏┛┃  ┃┗━━┓┃┗━┛┃┃┃╋┃┃╋┃┃┃┃┗┓┗┛┏  ┗━━┓┃┃┏━┓┃┃┗━┛┃╋┃┃┃┃╋┗┓┏┛  ┃┗━┛┃┃┃╋┃┃┃┏━┓┃┏┛┗┛┃╋╋┃┃  ┗━━━┛┗┛╋┗┛┗┛╋┗┛┗━━━┛╋╋┗┛ CHECK MY VIDEOS AND SUBSCRIBE AND LIKE PLZZ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1121</th>\n",
              "      <td>Eanna Cusack</td>\n",
              "      <td>Im just to check how much views it has﻿</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               author                                                                                                                                                                                                          text\n",
              "1206     zhichao wang                                                                                                                 i think about 100 millions of the views come from people who only wanted to  check the views﻿\n",
              "284   Vitaly Denisovs                                                                                                                                   Need money ? check my channel and subscribe,soon will post how to get it )﻿\n",
              "778      Bob Kanowski                                                                                                                                i turned it on mute as soon is i came on i just wanted to check the  views...﻿\n",
              "1039        Soundhase                                                                                          Hi Guys! check this awesome EDM &amp; House mix :) thanks a lot..  https://soundcloud.com/soundhase/edm-house-mix-2﻿\n",
              "1013      BeBe Burkey                                                                                                                                           and u should.d check my channel and tell me what I should do next!﻿\n",
              "958           Prim N.                                                                                                                 Just coming to check if people are still viewing this video. And  apparently, they still do.﻿\n",
              "881          Owen Lai                                                                                                                                                                                      just checking the views﻿\n",
              "777           Angek95                                                                                                                                                                                    Check my channel, please!﻿\n",
              "510       MrJtill0317  ┏━━━┓┏┓╋┏┓┏━━━┓┏━━━┓┏┓╋╋┏┓  ┃┏━┓┃┃┃╋┃┃┃┏━┓┃┗┓┏┓┃┃┗┓┏┛┃  ┃┗━━┓┃┗━┛┃┃┃╋┃┃╋┃┃┃┃┗┓┗┛┏  ┗━━┓┃┃┏━┓┃┃┗━┛┃╋┃┃┃┃╋┗┓┏┛  ┃┗━┛┃┃┃╋┃┃┃┏━┓┃┏┛┗┛┃╋╋┃┃  ┗━━━┛┗┛╋┗┛┗┛╋┗┛┗━━━┛╋╋┗┛ CHECK MY VIDEOS AND SUBSCRIBE AND LIKE PLZZ\n",
              "1121     Eanna Cusack                                                                                                                                                                       Im just to check how much views it has﻿"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTavbLpUDxjH"
      },
      "source": [
        "Most of these are SPAM, but a good number are false positives.\n",
        "**To keep precision high (while not sacrificing much in terms of coverage), we'd choose our regex-based rule.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS2T7z9kDxjH"
      },
      "source": [
        "### e) Writing an LF that uses a third-party model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_E_ZnizDxjH"
      },
      "source": [
        "The LF interface is extremely flexible, and can wrap existing models.\n",
        "A common technique is to use a commodity model trained for other tasks that are related to, but not the same as, the one we care about.\n",
        "\n",
        "For example, the [TextBlob](https://textblob.readthedocs.io/en/dev/index.html) tool provides a pretrained sentiment analyzer. Our spam classification task is not the same as sentiment classification, but we may believe that `SPAM` and `HAM` comments have different distributions of sentiment scores.\n",
        "We'll focus on writing LFs for `HAM`, since we identified `SPAM` comments above.\n",
        "\n",
        "**A brief intro to `Preprocessor`s**\n",
        "\n",
        "A [Snorkel `Preprocessor`](https://snorkel.readthedocs.io/en/master/packages/_autosummary/preprocess/snorkel.preprocess.Preprocessor.html#snorkel.preprocess.Preprocessor)\n",
        "is constructed from a black-box Python function that maps a data point to a new data point.\n",
        "`LabelingFunction`s can use `Preprocessor`s, which lets us write LFs over transformed or enhanced data points.\n",
        "We add the [`@preprocessor(...)` decorator](https://snorkel.readthedocs.io/en/master/packages/_autosummary/preprocess/snorkel.preprocess.preprocessor.html)\n",
        "to preprocessing functions to create `Preprocessor`s.\n",
        "`Preprocessor`s also have extra functionality, such as memoization\n",
        "(i.e. input/output caching, so it doesn't re-execute for each LF that uses it).\n",
        "\n",
        "We'll start by creating a `Preprocessor` that runs `TextBlob` on our comments, then extracts the polarity and subjectivity scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34ecW26qDxjI"
      },
      "source": [
        "from snorkel.preprocess import preprocessor\n",
        "from textblob import TextBlob\n",
        "\n",
        "\n",
        "@preprocessor(memoize=True)\n",
        "def textblob_sentiment(x):\n",
        "    scores = TextBlob(x.text)\n",
        "    x.polarity = scores.sentiment.polarity\n",
        "    x.subjectivity = scores.sentiment.subjectivity\n",
        "    return x"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAyL_XBjDxjI"
      },
      "source": [
        "We can now pick a reasonable threshold and write a corresponding labeling function (note that it doesn't have to be perfect as the `LabelModel` will soon help us estimate each labeling function's accuracy and reweight their outputs accordingly):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3Imoh8yDxjI"
      },
      "source": [
        "@labeling_function(pre=[textblob_sentiment])\n",
        "def textblob_polarity(x):\n",
        "    return HAM if x.polarity > 0.9 else ABSTAIN"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaNJJmo6DxjI"
      },
      "source": [
        "Let's do the same for the subjectivity scores.\n",
        "This will run faster than the last cell, since we memoized the `Preprocessor` outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnikWlvuDxjI"
      },
      "source": [
        "@labeling_function(pre=[textblob_sentiment])\n",
        "def textblob_subjectivity(x):\n",
        "    return HAM if x.subjectivity >= 0.5 else ABSTAIN"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acVNO0QlDxjI"
      },
      "source": [
        "Let's apply our LFs so we can analyze their performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "md-exclude-output"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4tXh6oRDxjI",
        "outputId": "1029fb98-ef85-46a7-85e3-969e6408f637"
      },
      "source": [
        "lfs = [textblob_polarity, textblob_subjectivity]\n",
        "\n",
        "applier = PandasLFApplier(lfs)\n",
        "L_train = applier.apply(df_train)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1564/1564 [00:01<00:00, 1340.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PME-SstDDxjJ",
        "outputId": "94ed904f-daf5-42ce-b047-0121abe3d890"
      },
      "source": [
        "LFAnalysis(L_train, lfs).lf_summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>j</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Coverage</th>\n",
              "      <th>Overlaps</th>\n",
              "      <th>Conflicts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>textblob_polarity</th>\n",
              "      <td>0</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.049872</td>\n",
              "      <td>0.021739</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>textblob_subjectivity</th>\n",
              "      <td>1</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.380435</td>\n",
              "      <td>0.021739</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       j Polarity  Coverage  Overlaps  Conflicts\n",
              "textblob_polarity      0      [0]  0.049872  0.021739        0.0\n",
              "textblob_subjectivity  1      [0]  0.380435  0.021739        0.0"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZd08Wr9DxjJ"
      },
      "source": [
        "**Again, these LFs aren't perfect—note that the `textblob_subjectivity` LF has fairly high coverage and could have a high rate of false positives. We'll rely on Snorkel's `LabelModel` to estimate the labeling function accuracies and reweight and combine their outputs accordingly.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZlwF8W2DxjJ"
      },
      "source": [
        "## 3. Writing More Labeling Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDFpjjLGDxjJ"
      },
      "source": [
        "If a single LF had high enough coverage to label our entire test dataset accurately, then we wouldn't need a classifier at all.\n",
        "We could just use that single simple heuristic to complete the task.\n",
        "But most problems are not that simple.\n",
        "Instead, we usually need to **combine multiple LFs** to label our dataset, both to increase the size of the generated training set (since we can't generate training labels for data points that no LF voted on) and to improve the overall accuracy of the training labels we generate by factoring in multiple different signals.\n",
        "\n",
        "In the following sections, we'll show just a few of the many types of LFs that you could write to generate a training dataset for this problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-7CKJeTDxjJ"
      },
      "source": [
        "### a) Keyword LFs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmJz4dT-DxjJ"
      },
      "source": [
        "For text applications, some of the simplest LFs to write are often just keyword lookups.\n",
        "These will often follow the same execution pattern, so we can create a template and use the `resources` parameter to pass in LF-specific keywords.\n",
        "Similar to the [`labeling_function` decorator](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.labeling_function.html#snorkel.labeling.labeling_function),\n",
        "the [`LabelingFunction` class](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.LabelingFunction.html#snorkel.labeling.LabelingFunction)\n",
        "wraps a Python function (the `f` parameter), and we can use the `resources` parameter to pass in keyword arguments (here, our keywords to lookup) to said function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THpEQsQpDxjJ"
      },
      "source": [
        "from snorkel.labeling import LabelingFunction\n",
        "\n",
        "\n",
        "def keyword_lookup(x, keywords, label):\n",
        "    if any(word in x.text.lower() for word in keywords):\n",
        "        return label\n",
        "    return ABSTAIN\n",
        "\n",
        "\n",
        "def make_keyword_lf(keywords, label=SPAM):\n",
        "    return LabelingFunction(\n",
        "        name=f\"keyword_{keywords[0]}\",\n",
        "        f=keyword_lookup,\n",
        "        resources=dict(keywords=keywords, label=label),\n",
        "    )\n",
        "\n",
        "\n",
        "\"\"\"Spam comments talk about 'my channel', 'my video', etc.\"\"\"\n",
        "keyword_my = make_keyword_lf(keywords=[\"my\"])\n",
        "\n",
        "\"\"\"Spam comments ask users to subscribe to their channels.\"\"\"\n",
        "keyword_subscribe = make_keyword_lf(keywords=[\"subscribe\"])\n",
        "\n",
        "\"\"\"Spam comments post links to other channels.\"\"\"\n",
        "keyword_link = make_keyword_lf(keywords=[\"http\"])\n",
        "\n",
        "\"\"\"Spam comments make requests rather than commenting.\"\"\"\n",
        "keyword_please = make_keyword_lf(keywords=[\"please\", \"plz\"])\n",
        "\n",
        "\"\"\"Ham comments actually talk about the video's content.\"\"\"\n",
        "keyword_song = make_keyword_lf(keywords=[\"song\"], label=HAM)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0SHggh4DxjK"
      },
      "source": [
        "### b) Pattern-matching LFs (regular expressions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMXR24srDxjK"
      },
      "source": [
        "If we want a little more control over a keyword search, we can look for regular expressions instead.\n",
        "The LF we developed above (`regex_check_out`) is an example of this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB1orhGjDxjK"
      },
      "source": [
        "### c)  Heuristic LFs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxtVSSJmDxjK"
      },
      "source": [
        "There may other heuristics or \"rules of thumb\" that you come up with as you look at the data.\n",
        "So long as you can express it in a function, it's a viable LF!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugSNU933DxjK"
      },
      "source": [
        "@labeling_function()\n",
        "def short_comment(x):\n",
        "    \"\"\"Ham comments are often short, such as 'cool video!'\"\"\"\n",
        "    return HAM if len(x.text.split()) < 5 else ABSTAIN"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h04q7EBADxjK"
      },
      "source": [
        "### d) LFs with Complex Preprocessors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvbg9JK8DxjK"
      },
      "source": [
        "Some LFs rely on fields that aren't present in the raw data, but can be derived from it.\n",
        "We can enrich our data (providing more fields for the LFs to refer to) using `Preprocessor`s.\n",
        "\n",
        "For example, we can use the fantastic NLP (natural language processing) tool [spaCy](https://spacy.io/) to add lemmas, part-of-speech (pos) tags, etc. to each token.\n",
        "Snorkel provides a prebuilt preprocessor for spaCy called `SpacyPreprocessor` which adds a new field to the\n",
        "data point containing a [spaCy `Doc` object](https://spacy.io/api/doc).\n",
        "For more info, see the [`SpacyPreprocessor` documentation](https://snorkel.readthedocs.io/en/master/packages/_autosummary/preprocess/snorkel.preprocess.nlp.SpacyPreprocessor.html#snorkel.preprocess.nlp.SpacyPreprocessor).\n",
        "\n",
        "\n",
        "If you prefer to use a different NLP tool, you can also wrap that as a `Preprocessor` and use it in the same way.\n",
        "For more info, see the [`preprocessor` documentation](https://snorkel.readthedocs.io/en/master/packages/_autosummary/preprocess/snorkel.preprocess.preprocessor.html#snorkel.preprocess.preprocessor)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "md-exclude"
        ],
        "id": "0Hio4nhdDxjK"
      },
      "source": [
        "If the spaCy English model wasn't already installed, the next cell may raise an exception.\n",
        "If this happens, restart the kernel and re-execute the cells up to this point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNAvd2tNDxjL"
      },
      "source": [
        "from snorkel.preprocess.nlp import SpacyPreprocessor\n",
        "\n",
        "# The SpacyPreprocessor parses the text in text_field and\n",
        "# stores the new enriched representation in doc_field\n",
        "spacy = SpacyPreprocessor(text_field=\"text\", doc_field=\"doc\", memoize=True)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtWdtAQIDxjL"
      },
      "source": [
        "@labeling_function(pre=[spacy])\n",
        "def has_person(x):\n",
        "    \"\"\"Ham comments mention specific people and are short.\"\"\"\n",
        "    if len(x.doc) < 20 and any([ent.label_ == \"PERSON\" for ent in x.doc.ents]):\n",
        "        return HAM\n",
        "    else:\n",
        "        return ABSTAIN"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOb2-VYRDxjL"
      },
      "source": [
        "Because spaCy is such a common preprocessor for NLP applications, we also provide a\n",
        "[prebuilt `labeling_function`-like decorator that uses spaCy](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.lf.nlp.nlp_labeling_function.html#snorkel.labeling.lf.nlp.nlp_labeling_function).\n",
        "This resulting LF is identical to the one defined manually above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_4QISrsDxjL"
      },
      "source": [
        "from snorkel.labeling.lf.nlp import nlp_labeling_function\n",
        "\n",
        "\n",
        "@nlp_labeling_function()\n",
        "def has_person_nlp(x):\n",
        "    \"\"\"Ham comments mention specific people and are short.\"\"\"\n",
        "    if len(x.doc) < 20 and any([ent.label_ == \"PERSON\" for ent in x.doc.ents]):\n",
        "        return HAM\n",
        "    else:\n",
        "        return ABSTAIN"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xwFg7H4DxjL"
      },
      "source": [
        "**Adding new domain-specific preprocessors and LF types is a great way to contribute to Snorkel!\n",
        "If you have an idea, feel free to reach out to the maintainers or submit a PR!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlXGcvpeDxjL"
      },
      "source": [
        "### e) Third-party Model LFs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U_nrKJ5DxjL"
      },
      "source": [
        "We can also utilize other models, including ones trained for other tasks that are related to, but not the same as, the one we care about.\n",
        "The TextBlob-based LFs we created above are great examples of this!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWHAGEgLDxjL"
      },
      "source": [
        "## 4. Combining Labeling Function Outputs with the Label Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3-ruAwqDxjL"
      },
      "source": [
        "This tutorial demonstrates just a handful of the types of LFs that one might write for this task.\n",
        "One of the key goals of Snorkel is _not_ to replace the effort, creativity, and subject matter expertise required to come up with these labeling functions, but rather to make it faster to write them, since **in Snorkel the labeling functions are assumed to be noisy, i.e. innaccurate, overlapping, etc.**\n",
        "Said another way: the LF abstraction provides a flexible interface for conveying a huge variety of supervision signals, and the `LabelModel` is able to denoise these signals, reducing the need for painstaking manual fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5PC7kaADxjM"
      },
      "source": [
        "lfs = [\n",
        "    keyword_my,\n",
        "    keyword_subscribe,\n",
        "    keyword_link,\n",
        "    keyword_please,\n",
        "    keyword_song,\n",
        "    regex_check_out,\n",
        "    short_comment,\n",
        "    has_person_nlp,\n",
        "    textblob_polarity,\n",
        "    textblob_subjectivity,\n",
        "]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHLLXvbHDxjM"
      },
      "source": [
        "With our full set of LFs, we can now apply these once again with `LFApplier` to get the label matrices.\n",
        "The Pandas format provides an easy interface that many practitioners are familiar with, but it is also less optimized for scale.\n",
        "For larger datasets, more compute-intensive LFs, or larger LF sets, you may decide to use one of the other data formats\n",
        "that Snorkel supports natively, such as Dask DataFrames or PySpark DataFrames, and their corresponding applier objects.\n",
        "For more info, check out the [Snorkel API documentation](https://snorkel.readthedocs.io/en/master/packages/labeling.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "md-exclude-output"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFphFcgZDxjM",
        "outputId": "f46d1279-972a-4c3c-b2ed-bdc0ddb09fb2"
      },
      "source": [
        "applier = PandasLFApplier(lfs=lfs)\n",
        "L_train = applier.apply(df=df_train)\n",
        "L_test = applier.apply(df=df_test)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1564/1564 [00:21<00:00, 71.91it/s]\n",
            "100%|██████████| 392/392 [00:05<00:00, 67.82it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "g3gCb_mKDxjM",
        "outputId": "d1ed19ad-7935-4832-b0ca-4912dcbe6bb9"
      },
      "source": [
        "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>j</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Coverage</th>\n",
              "      <th>Overlaps</th>\n",
              "      <th>Conflicts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>keyword_my</th>\n",
              "      <td>0</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.200128</td>\n",
              "      <td>0.189258</td>\n",
              "      <td>0.117647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>keyword_subscribe</th>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.129156</td>\n",
              "      <td>0.108056</td>\n",
              "      <td>0.072251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>keyword_http</th>\n",
              "      <td>2</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.102941</td>\n",
              "      <td>0.085678</td>\n",
              "      <td>0.070332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>keyword_please</th>\n",
              "      <td>3</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.109335</td>\n",
              "      <td>0.106138</td>\n",
              "      <td>0.057545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>keyword_song</th>\n",
              "      <td>4</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.155371</td>\n",
              "      <td>0.126598</td>\n",
              "      <td>0.049872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>regex_check_out</th>\n",
              "      <td>5</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.228900</td>\n",
              "      <td>0.139386</td>\n",
              "      <td>0.095908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>short_comment</th>\n",
              "      <td>6</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.250639</td>\n",
              "      <td>0.159847</td>\n",
              "      <td>0.063939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>has_person_nlp</th>\n",
              "      <td>7</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.068414</td>\n",
              "      <td>0.051790</td>\n",
              "      <td>0.021100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>textblob_polarity</th>\n",
              "      <td>8</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.049872</td>\n",
              "      <td>0.045396</td>\n",
              "      <td>0.006394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>textblob_subjectivity</th>\n",
              "      <td>9</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.380435</td>\n",
              "      <td>0.286445</td>\n",
              "      <td>0.166880</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       j Polarity  Coverage  Overlaps  Conflicts\n",
              "keyword_my             0      [1]  0.200128  0.189258   0.117647\n",
              "keyword_subscribe      1      [1]  0.129156  0.108056   0.072251\n",
              "keyword_http           2      [1]  0.102941  0.085678   0.070332\n",
              "keyword_please         3      [1]  0.109335  0.106138   0.057545\n",
              "keyword_song           4      [0]  0.155371  0.126598   0.049872\n",
              "regex_check_out        5      [1]  0.228900  0.139386   0.095908\n",
              "short_comment          6      [0]  0.250639  0.159847   0.063939\n",
              "has_person_nlp         7      [0]  0.068414  0.051790   0.021100\n",
              "textblob_polarity      8      [0]  0.049872  0.045396   0.006394\n",
              "textblob_subjectivity  9      [0]  0.380435  0.286445   0.166880"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzB14WcvDxjM"
      },
      "source": [
        "Our goal is now to convert the labels from our LFs into a single _noise-aware_ probabilistic (or confidence-weighted) label per data point.\n",
        "A simple baseline for doing this is to take the majority vote on a per-data point basis: if more LFs voted SPAM than HAM, label it SPAM (and vice versa).\n",
        "We can test this with the\n",
        "[`MajorityLabelVoter` baseline model](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.model.baselines.MajorityLabelVoter.html#snorkel.labeling.model.baselines.MajorityLabelVoter)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "md-exclude-output"
        ],
        "id": "9Y4-8qV8DxjN"
      },
      "source": [
        "from snorkel.labeling.model import MajorityLabelVoter\n",
        "\n",
        "majority_model = MajorityLabelVoter()\n",
        "preds_train = majority_model.predict(L=L_train)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUL607bEX-ZF"
      },
      "source": [
        "majority_probs_train = majority_model.predict_proba(L=L_train)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-VS2JOCDxjN",
        "outputId": "6f47ee08-a30d-4aea-a8e7-5e4af01b5d6f"
      },
      "source": [
        "majority_probs_train"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1. , 0. ],\n",
              "       [1. , 0. ],\n",
              "       [0.5, 0.5],\n",
              "       ...,\n",
              "       [0.5, 0.5],\n",
              "       [0.5, 0.5],\n",
              "       [0.5, 0.5]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC_FLLpQDxjO"
      },
      "source": [
        "### Filtering out unlabeled data points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0ccx2jzDxjO"
      },
      "source": [
        "As we saw earlier, some of the data points in our `train` set received no labels from any of our LFs.\n",
        "These data points convey no supervision signal and tend to hurt performance, so we filter them out before training using a\n",
        "[built-in utility](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.filter_unlabeled_dataframe.html#snorkel.labeling.filter_unlabeled_dataframe)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ9hl0_qDxjO"
      },
      "source": [
        "from snorkel.labeling import filter_unlabeled_dataframe\n",
        "\n",
        "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
        "    X=df_train, y=majority_probs_train, L=L_train\n",
        ")"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlYQG9D_DxjO"
      },
      "source": [
        "## 5. Training a Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvuKQpF2DxjO"
      },
      "source": [
        "### Featurization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8MmZCGIDxjO"
      },
      "source": [
        "For simplicity and speed, we use a simple \"bag of n-grams\" feature representation: each data point is represented by a one-hot vector marking which words or 2-word combinations are present in the comment text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "md-exclude-output"
        ],
        "id": "rHmWJ5wKDxjO"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(ngram_range=(1, 5))\n",
        "X_train = vectorizer.fit_transform(df_train_filtered.text.tolist())\n",
        "X_test = vectorizer.transform(df_test.text.tolist())"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE36oeUEK1Lk"
      },
      "source": [
        "Y_test = df_test['class'].values"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9xe8H1HDxjO"
      },
      "source": [
        "### Scikit-Learn Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuhUvEKNDxjP"
      },
      "source": [
        "As we saw in Section 4, the `LabelModel` outputs probabilistic (float) labels.\n",
        "If the classifier we are training accepts target labels as floats, we can train on these labels directly (see describe the properties of this type of \"noise-aware\" loss in our [NeurIPS 2016 paper](https://arxiv.org/abs/1605.07723)).\n",
        "\n",
        "If we want to use a library or model that doesn't accept probabilistic labels (such as Scikit-Learn), we can instead replace each label distribution with the label of the class that has the maximum probability.\n",
        "This can easily be done using the\n",
        "[`probs_to_preds` helper method](https://snorkel.readthedocs.io/en/master/packages/_autosummary/utils/snorkel.utils.probs_to_preds.html#snorkel.utils.probs_to_preds).\n",
        "We do note, however, that this transformation is lossy, as we no longer have values for our confidence in each label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4KjzHK6DxjP"
      },
      "source": [
        "from snorkel.utils import probs_to_preds\n",
        "\n",
        "preds_train_filtered = probs_to_preds(probs=probs_train_filtered)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqzHQvcIDxjP"
      },
      "source": [
        "We then use these labels to train a classifier as usual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "md-exclude-output"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1iE3wHTDxjP",
        "outputId": "5449c23c-b45e-4235-9cdd-7327c0515d00"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "sklearn_model = LogisticRegression(C=1e3, solver=\"liblinear\")\n",
        "sklearn_model.fit(X=X_train, y=preds_train_filtered)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1000.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFm2NiUUDxjP",
        "outputId": "f3336a63-58a3-4a2a-c021-0ba97879f8b6"
      },
      "source": [
        "print(f\"Test Accuracy: {sklearn_model.score(X=X_test, y=Y_test) * 100:.1f}%\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 86.2%\n"
          ]
        }
      ]
    }
  ]
}